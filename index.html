<!doctype html>



  


<html class="theme-next mist use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>






<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta property="og:type" content="website">
<meta property="og:title" content="Deep Learning Journey">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Deep Learning Journey">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Deep Learning Journey">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>Deep Learning Journey</title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  














  
  
    
  

  <div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Deep Learning Journey</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/05/03/Comparision of Matlab, R and Python/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mike">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Deep Learning Journey">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/05/03/Comparision of Matlab, R and Python/" itemprop="url">
                  Comparision of Matlab, Python and R
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-05-03T00:00:00+10:00">
                2017-05-03
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Deep-Learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/05/03/Comparision of Matlab, R and Python/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2017/05/03/Comparision of Matlab, R and Python/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

          
        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>Matlab, Python and R are all REPL languages, which stands for Read, Evaluation, Print and then Loop, are all scripting languages as well.</p>
</blockquote>
<p>Above three RPEL languages are much faster to write/debug codes than C++/C#/Java. It’s ideal for research and backtesting with very strong vectorize calculation capabilities.</p>
<h2 id="MATLAB"><a href="#MATLAB" class="headerlink" title="MATLAB"></a>MATLAB</h2><p>MATLAB is a corporate development platform that has numerous native toolboxes, such as Statistics and machine learning, financial instruments, GARCH, neural networks and so on, can be compiled into C/C++ for better performance. But it’s a little bit expensive for SME and individuals, although there’re some corresponding freewares.</p>
<h2 id="R"><a href="#R" class="headerlink" title="R"></a>R</h2><p>R is similar with MATLAB, and it’s <strong>FREE</strong>. R has a larger collection of advanced packages created by academic researchers. But R is slow and cannot be compiled into C/C++.</p>
<h2 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h2><p>Python is <strong>FREE</strong> as well. In order to utilize vectorized capabilities, it’s a must to install SciPy package to enable that. Pandas extension of Python is a quite handy tool for data manipulation and analysis, which can call R library. Moreover, Python can be compiled into C/C++ for better performance and via Numba, it can run on GPU.</p>
<h2 id="Comparison-of-MATLAB-Python-and-R"><a href="#Comparison-of-MATLAB-Python-and-R" class="headerlink" title="Comparison of MATLAB, Python and R"></a>Comparison of MATLAB, Python and R</h2><p><em>1 for best</em></p>
<table>
<thead>
<tr>
<th>Features</th>
<th style="text-align:center">MATLAB</th>
<th style="text-align:center">R</th>
<th style="text-align:center">Python</th>
</tr>
</thead>
<tbody>
<tr>
<td>Easy for Use</td>
<td style="text-align:center">1</td>
<td style="text-align:center">2</td>
<td style="text-align:center">2</td>
</tr>
<tr>
<td>IDE</td>
<td style="text-align:center">1</td>
<td style="text-align:center">3</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td>Speed</td>
<td style="text-align:center">1</td>
<td style="text-align:center">3</td>
<td style="text-align:center">2</td>
</tr>
<tr>
<td>Toolboxes</td>
<td style="text-align:center">2</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td>Into C/C++</td>
<td style="text-align:center">1</td>
<td style="text-align:center">N/A</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td>Price</td>
<td style="text-align:center">2</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
</tr>
</tbody>
</table>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/03/28/ML Review/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mike">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Deep Learning Journey">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/03/28/ML Review/" itemprop="url">
                  Learning Path
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-03-28T00:00:00+11:00">
                2017-03-28
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Deep-Learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/03/28/ML Review/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2017/03/28/ML Review/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

          
        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>Review of recent ML learning</p>
</blockquote>
<p>Andrew Ng’s ML course on Coursera is an entry level course for machine learning, which give me a good understanding of supervised learning like linear regression, logistic regression and SVM, as well as unsupervised learning such as K-Means, Abnormaly detection. But all these concept are mostly like the traditional data mining skills and method. If someone like me wanna to dive into more deep area, there’re still lots of things to learn.</p>
<h2 id="Machine-Learning-Course-Final-Score"><a href="#Machine-Learning-Course-Final-Score" class="headerlink" title="Machine Learning Course Final Score"></a>Machine Learning Course Final Score</h2><p><img src="/images/Score/&quot;ML-Final&quot;.png" alt="Score"></p>
<h2 id="The-next-learning-path"><a href="#The-next-learning-path" class="headerlink" title="The next learning path"></a>The next learning path</h2><ol>
<li>Complete CS229 course of Stanford, this is a totaly different course by Andrew Ng for Machine Learning.</li>
<li>Complete Neural Network for ML course by Geoffrey Hinton. This is a little bit harder course because of more mathmaticial knowledges.</li>
<li>Complete CS231n course of Stanford, this is a visual recognition course using convolutional neural network, which is a very hot deep learning net.</li>
<li>Complete David Silver’s Reinforcement Learning Course.</li>
<li>Complete CS294 Deep Reinforcement Learning Course of UCB.</li>
<li>Complte Deep Learning course of Udacity, in this course using tensorflow as it ML development framework.</li>
</ol>
<h2 id="Learning-object"><a href="#Learning-object" class="headerlink" title="Learning object"></a>Learning object</h2><ol>
<li>Familiar with at least one ML development framework like tensorflow, keras, theano.</li>
<li>Be good at one Deep Net such as Convolutional Neural Network, Recurrent Neural Network.</li>
<li>Complete a project focusing on Algorithm Trading or credit policy management using deep learning technology.</li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/03/25/2017-03-25-Assignment Solutions-8-9weeks/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mike">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Deep Learning Journey">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/03/25/2017-03-25-Assignment Solutions-8-9weeks/" itemprop="url">
                  Assignment Solutions for Week 8 to 9
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-03-25T00:00:00+11:00">
                2017-03-25
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Assignment-Solution/" itemprop="url" rel="index">
                    <span itemprop="name">Assignment-Solution</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/03/25/2017-03-25-Assignment Solutions-8-9weeks/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2017/03/25/2017-03-25-Assignment Solutions-8-9weeks/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

          
        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>Week 8 to 9 Assignment Solutions</p>
</blockquote>
<p>Completed all 11 weeks ML course on Coursera last week. It’s a fundermental class which focus on essential concepts of traditional ML, mostly like data mining technologies. Only touch a little bit of deep learning. Very good for ML introductory.</p>
<h2 id="Week-8-K-Means-Clustering-and-PCA"><a href="#Week-8-K-Means-Clustering-and-PCA" class="headerlink" title="Week 8: K-Means Clustering and PCA"></a>Week 8: K-Means Clustering and PCA</h2><p><strong>Find Closest Centroids</strong></p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="built_in">size</span>(X,<span class="number">1</span>)</div><div class="line">  tmp=(X(<span class="built_in">i</span>,:)-centroids).^<span class="number">2</span>;</div><div class="line">  dist=<span class="built_in">zeros</span>(<span class="built_in">size</span>(X,<span class="number">1</span>),<span class="number">1</span>);</div><div class="line">  <span class="keyword">for</span> <span class="built_in">j</span>=<span class="number">1</span>:K</div><div class="line">    value=sum(tmp(<span class="built_in">j</span>,:));</div><div class="line">    <span class="keyword">if</span> <span class="built_in">j</span>==<span class="number">1</span></div><div class="line">      idx(<span class="built_in">i</span>)=<span class="number">1</span>;</div><div class="line">      dist=value;</div><div class="line">    <span class="keyword">elseif</span> dist&gt;value</div><div class="line">      idx(<span class="built_in">i</span>)=<span class="built_in">j</span>;</div><div class="line">      dist=value;</div><div class="line">    <span class="keyword">end</span></div><div class="line">  <span class="keyword">end</span>  </div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure>
<p><strong>Compute Centroid Means</strong><br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:K</div><div class="line">  v=<span class="built_in">find</span>(idx==<span class="built_in">i</span>);</div><div class="line">  centroids(<span class="built_in">i</span>,:)=sum(X(v,:))/<span class="built_in">size</span>(v,<span class="number">1</span>);</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure></p>
<p><strong>PCA</strong><br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sigma=(X'*X)/m;</div><div class="line">[U, S, V]=svd(sigma);</div></pre></td></tr></table></figure></p>
<p><strong>Project Data</strong><br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="built_in">length</span>(X)</div><div class="line">  x=X(<span class="built_in">i</span>,:)';</div><div class="line">  Z(<span class="built_in">i</span>,:)=x'*U(:,<span class="number">1</span>:K);</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure></p>
<p><strong>Recover Data</strong><br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="built_in">length</span>(Z)</div><div class="line">  <span class="keyword">for</span> <span class="built_in">j</span>=<span class="number">1</span>:<span class="built_in">length</span>(U)</div><div class="line">    X_rec(<span class="built_in">i</span>,<span class="built_in">j</span>)=Z(<span class="built_in">i</span>,:)*U(<span class="built_in">j</span>,<span class="number">1</span>:K)';</div><div class="line">  <span class="keyword">end</span></div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure></p>
<h2 id="Week-9-Anomaly-Detection-and-Recommender-Systems"><a href="#Week-9-Anomaly-Detection-and-Recommender-Systems" class="headerlink" title="Week 9: Anomaly Detection and Recommender Systems"></a>Week 9: Anomaly Detection and Recommender Systems</h2><p><strong>Estimate Gaussian Parameters</strong><br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">mu=sum(X(:,<span class="number">1</span>:<span class="keyword">end</span>))/m;</div><div class="line">sigma2=sum((X-mu).^<span class="number">2</span>)/m</div></pre></td></tr></table></figure></p>
<p><strong>Select Threshhold</strong><br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">pred=(pval&lt;epsilon);</div><div class="line">tp=sum((pred==<span class="number">1</span>)&amp;(yval==<span class="number">1</span>));</div><div class="line">fp=sum((pred==<span class="number">1</span>)&amp;(yval==<span class="number">0</span>));</div><div class="line">fn=sum((pred==<span class="number">1</span>)&amp;(yval==<span class="number">0</span>));</div><div class="line">precision=tp/(tp+fp);</div><div class="line">recall=tp/(tp+fn);</div><div class="line">F1=<span class="number">2</span>*precision*recall/(precision+recall)</div></pre></td></tr></table></figure></p>
<p><strong>Collaborative Filtering Cost/Gradient with Regularization</strong><br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">cost=(X*Theta'-Y);</div><div class="line">J=sum(sum((cost.^<span class="number">2</span>).*R))/<span class="number">2</span>;</div><div class="line">J=J+(lambda/<span class="number">2</span>)*sum(sum(Theta.^<span class="number">2</span>))+(lambda/<span class="number">2</span>)*sum(sum(X.^<span class="number">2</span>));</div><div class="line"></div><div class="line">X_grad=(cost.*R)*Theta;</div><div class="line">X_grad+=lambda*X;</div><div class="line"></div><div class="line">Theta_grad=(cost.*R)'*X;</div><div class="line">Theta_grad+=lambda*Theta;</div></pre></td></tr></table></figure></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/03/17/2017-03-17-Assignment Solution-4to7weeks/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mike">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Deep Learning Journey">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/03/17/2017-03-17-Assignment Solution-4to7weeks/" itemprop="url">
                  Assignment Solutions for Week 5 to 7
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-03-17T00:00:00+11:00">
                2017-03-17
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Assignment-Solution/" itemprop="url" rel="index">
                    <span itemprop="name">Assignment-Solution</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/03/17/2017-03-17-Assignment Solution-4to7weeks/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2017/03/17/2017-03-17-Assignment Solution-4to7weeks/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

          
        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>Week 5 to 7 Assignment Solutions</p>
<h2 id="Week-5-Neural-Network-Learning"><a href="#Week-5-Neural-Network-Learning" class="headerlink" title="Week 5: Neural Network Learning"></a>Week 5: Neural Network Learning</h2><p><strong>Feedforward and cost function</strong></p>
</blockquote>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">X=[ones(size(X,<span class="number">1</span>),<span class="number">1</span>) X];</div><div class="line"></div><div class="line">yVec=[zeros(size(y,<span class="number">1</span>),num_labels)];</div><div class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:m</div><div class="line">  yVec(<span class="built_in">i</span>,y(<span class="built_in">i</span>))=<span class="number">1</span>;</div><div class="line"><span class="keyword">end</span></div><div class="line"></div><div class="line">a1=X;</div><div class="line">z2=X*Theta1';</div><div class="line">a2=sigmoid(z2);</div><div class="line">a2=[ones(size(a1,<span class="number">1</span>),<span class="number">1</span>) a2];</div><div class="line">z3=a2*Theta2';</div><div class="line">hy=a3=sigmoid(z3);</div><div class="line"></div><div class="line">J=sum(sum((-yVec).*<span class="built_in">log</span>(hy)-(<span class="number">1</span>-yVec).*<span class="built_in">log</span>(<span class="number">1</span>-hy)))/m;</div><div class="line">J=J+(lambda/(<span class="number">2</span>*m))*(sum(sum(Theta1(:,<span class="number">2</span>:<span class="keyword">end</span>).^<span class="number">2</span>))+sum(sum(Theta2(:,<span class="number">2</span>:<span class="keyword">end</span>).^<span class="number">2</span>)));</div><div class="line"></div><div class="line">delta3=hy-yVec;</div><div class="line">Theta2_grad=(Theta2_grad+delta3'*a2)/m;</div><div class="line">  </div><div class="line">delta2=(delta3*Theta2)(:,<span class="number">2</span>:<span class="keyword">end</span>).*sigmoidGradient(z2);  </div><div class="line">Theta1_grad=(Theta1_grad+delta2'*X)/m;</div><div class="line"></div><div class="line">Theta1_grad=Theta1_grad+(lambda/m)*[zeros(size(Theta1,<span class="number">1</span>),<span class="number">1</span>) Theta1(:,<span class="number">2</span>:end)];</div><div class="line">Theta2_grad=Theta2_grad+(lambda*[zeros(size(Theta2,<span class="number">1</span>),<span class="number">1</span>) Theta2(:,<span class="number">2</span>:end)])/m;</div></pre></td></tr></table></figure>
<p><strong>Sigmoid Gradient</strong><br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">g=<span class="built_in">ones</span>(<span class="built_in">size</span>(z))./(<span class="number">1</span>+<span class="built_in">exp</span>(-z));</div><div class="line">g=g.*(<span class="number">1</span>-g);</div></pre></td></tr></table></figure></p>
<p><strong>Regularized Gradient</strong><br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">numgrad = <span class="built_in">zeros</span>(<span class="built_in">size</span>(theta));</div><div class="line">perturb = <span class="built_in">zeros</span>(<span class="built_in">size</span>(theta));</div><div class="line">e = <span class="number">1e-4</span>;</div><div class="line"><span class="keyword">for</span> p = <span class="number">1</span>:<span class="built_in">numel</span>(theta)</div><div class="line">    <span class="comment">% Set perturbation vector</span></div><div class="line">    perturb(p) = e;</div><div class="line">    loss1 = J(theta - perturb);</div><div class="line">    loss2 = J(theta + perturb);</div><div class="line">    <span class="comment">% Compute Numerical Gradient</span></div><div class="line">    numgrad(p) = (loss2 - loss1) / (<span class="number">2</span>*e);</div><div class="line">    perturb(p) = <span class="number">0</span>;</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure></p>
<h2 id="Week-6-Regularized-Linear-Regression-and-Bias-Variance"><a href="#Week-6-Regularized-Linear-Regression-and-Bias-Variance" class="headerlink" title="Week 6: Regularized Linear Regression and Bias-Variance"></a>Week 6: Regularized Linear Regression and Bias-Variance</h2><p><strong>regularized linear regression</strong><br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">J=sum((X*theta-y).^<span class="number">2</span>)/(<span class="number">2</span>*m);</div><div class="line">J=J+lambda*sum(theta(<span class="number">2</span>:<span class="keyword">end</span>).^<span class="number">2</span>)/(<span class="number">2</span>*m);</div><div class="line"></div><div class="line">grad(<span class="number">1</span>)=(X'(<span class="number">1</span>,:)*(X*theta-y))/m;</div><div class="line">grad(<span class="number">2</span>:<span class="keyword">end</span>)=(X'(<span class="number">2</span>:<span class="keyword">end</span>,:)*(X*theta-y))/m+(lambda/m)*theta(<span class="number">2</span>:<span class="keyword">end</span>);</div></pre></td></tr></table></figure></p>
<p><strong>Learning Curve</strong><br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:m</div><div class="line">  theta = <span class="built_in">ones</span>(<span class="built_in">size</span>(X,<span class="number">2</span>),<span class="number">1</span>);</div><div class="line">  <span class="comment">%[J_train, grad]=linearRegCostFunction(X(1:i,:), y(1:i,:), theta, lambda);</span></div><div class="line">  [theta] = trainLinearReg(X(<span class="number">1</span>:<span class="built_in">i</span>,:), y(<span class="number">1</span>:<span class="built_in">i</span>,:), lambda);</div><div class="line">  [J_train,grad]=linearRegCostFunction(X(<span class="number">1</span>:<span class="built_in">i</span>,:), y(<span class="number">1</span>:<span class="built_in">i</span>,:), theta, <span class="number">0</span>);</div><div class="line">  error_train(<span class="built_in">i</span>)=J_train;</div><div class="line">  [J_val, grad]=linearRegCostFunction(Xval, yval, theta, <span class="number">0</span>);</div><div class="line">  error_val(<span class="built_in">i</span>)=J_val;</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure></p>
<p><strong>Polynomial Feature Mapping</strong><br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">2</span>:p</div><div class="line">  X=[X X(:,<span class="number">1</span>).^i];</div><div class="line"><span class="keyword">end</span></div><div class="line"></div><div class="line">X_poly=X;</div></pre></td></tr></table></figure></p>
<p><strong>Validation Curve</strong><br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="built_in">length</span>(lambda_vec)</div><div class="line">      lambda=lambda_vec(<span class="built_in">i</span>)</div><div class="line">      [theta] = trainLinearReg(X, y, lambda);</div><div class="line">      [J_train,grad]=linearRegCostFunction(X, y, theta, <span class="number">0</span>);</div><div class="line">      error_train(<span class="built_in">i</span>)=J_train;</div><div class="line">      [J_val, grad]=linearRegCostFunction(Xval, yval, theta, <span class="number">0</span>);</div><div class="line">      error_val(<span class="built_in">i</span>)=J_val;</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure></p>
<h2 id="Week-7-Support-Vector-Machines"><a href="#Week-7-Support-Vector-Machines" class="headerlink" title="Week 7: Support Vector Machines"></a>Week 7: Support Vector Machines</h2><p><strong>Guassian Kernel</strong><br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">x=sum((x1-x2).^<span class="number">2</span>);</div><div class="line">sim=<span class="built_in">exp</span>(-x/(<span class="number">2</span>*sigma*sigma));</div></pre></td></tr></table></figure></p>
<p><strong>Parameters (C, Sigma) for dataset3</strong><br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">idx=<span class="number">1</span>;</div><div class="line">result=<span class="built_in">zeros</span>(<span class="number">64</span>,<span class="number">3</span>);</div><div class="line"><span class="keyword">for</span> C = [<span class="number">0.01</span> <span class="number">0.03</span> <span class="number">0.1</span> <span class="number">0.3</span> <span class="number">1</span> <span class="number">3</span> <span class="number">10</span> <span class="number">30</span>]</div><div class="line">  <span class="keyword">for</span> sigma = [<span class="number">0.01</span> <span class="number">0.03</span> <span class="number">0.1</span> <span class="number">0.3</span> <span class="number">1</span> <span class="number">3</span> <span class="number">10</span> <span class="number">30</span>]</div><div class="line">    model=svmTrain(X,y,C,@(x1,x2) gaussianKernel(x1,x2,sigma));</div><div class="line">    predictions=svmPredict(model,Xval);</div><div class="line">    result(idx,:)=[C sigma mean(double(predictions~=yval))];</div><div class="line">    idx+=<span class="number">1</span>;</div><div class="line"><span class="keyword">end</span></div><div class="line">pos=<span class="built_in">find</span>(result(:,<span class="number">3</span>)==min(result(:,<span class="number">3</span>)));</div><div class="line">C=result(pos,<span class="number">1</span>);</div><div class="line">sigma=result(pos,<span class="number">2</span>);</div></pre></td></tr></table></figure></p>
<p><strong>Email Preprocessing</strong><br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="built_in">length</span>(vocabList)</div><div class="line">  <span class="keyword">if</span> (strcmp(str,vocabList&#123;i&#125;)==<span class="number">1</span>)</div><div class="line">    word_indices=[word_indices;i];</div><div class="line">  <span class="keyword">end</span></div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure></p>
<p><strong>Email Feature Extraction</strong><br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="built_in">length</span>(word_indices)</div><div class="line">  idx=word_indices(<span class="built_in">i</span>);</div><div class="line">  x(idx)=<span class="number">1</span>;</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/03/06/2017-03-06-First-4-Weeks-Assignment-Solutions/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mike">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Deep Learning Journey">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/03/06/2017-03-06-First-4-Weeks-Assignment-Solutions/" itemprop="url">
                  First 4 Weeks Assignment Solutions
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-03-06T00:00:00+11:00">
                2017-03-06
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Assignment-Solution/" itemprop="url" rel="index">
                    <span itemprop="name">Assignment-Solution</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/03/06/2017-03-06-First-4-Weeks-Assignment-Solutions/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2017/03/06/2017-03-06-First-4-Weeks-Assignment-Solutions/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

          
        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>Week 1 to 4 Assignment Solutions</p>
<h2 id="Week-1-Introduction"><a href="#Week-1-Introduction" class="headerlink" title="Week 1: Introduction"></a>Week 1: Introduction</h2><p><strong>No Assignment</strong></p>
</blockquote>
<h2 id="Week-2-Linear-Regression"><a href="#Week-2-Linear-Regression" class="headerlink" title="Week 2: Linear Regression"></a>Week 2: Linear Regression</h2><p><strong>Warm Up Exercise</strong><br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">A = <span class="built_in">eye</span>(<span class="number">5</span>);</div></pre></td></tr></table></figure></p>
<p><strong>Compute Cost For One Variable</strong><br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">J=sum((X*theta-y).^<span class="number">2</span>)/(<span class="number">2</span>*m);</div></pre></td></tr></table></figure></p>
<p><strong>Gradient Descent For One Variable</strong><br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> iter = <span class="number">1</span>:num_iters</div><div class="line">	theta = theta - alpha / m * ((X * theta - y)'* X)';</div><div class="line">	J_history(iter) = computeCost(X, y, theta);</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure></p>
<p><strong>Feature Normalization</strong><br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">mu=mean(X);</div><div class="line">sigma=std(X);</div><div class="line">X_norm=(X-mu)./sigma;</div></pre></td></tr></table></figure></p>
<p><strong>Compute Cost For Multiple Variable</strong><br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">J=((X*theta-y)'*(X*theta-y))/(<span class="number">2</span>*m);</div></pre></td></tr></table></figure></p>
<p><strong>Gradient Descent For Multiple Variable</strong><br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> iter = <span class="number">1</span>:num_iters</div><div class="line">	theta=theta-(alpha/m)*(X'*((X*theta)-y));</div><div class="line">	J_history(iter) = computeCostMulti(X, y, theta);</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure></p>
<p><strong>Normal Equations</strong><br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">theta=pinv(X'*X)*X'*y;</div></pre></td></tr></table></figure></p>
<h2 id="Week-3-Logistic-Regression"><a href="#Week-3-Logistic-Regression" class="headerlink" title="Week 3: Logistic Regression"></a>Week 3: Logistic Regression</h2><p><strong>Sigmoid Function</strong><br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">g=<span class="number">1.0</span>./(<span class="number">1.0</span>+<span class="built_in">exp</span>(-z));</div></pre></td></tr></table></figure></p>
<p><strong>Compute Cost for Logistic Regression</strong><br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">J=<span class="number">1</span>/m*sum((-y)'*<span class="built_in">log</span>(sigmoid(X*theta))-(<span class="number">1</span>-y)'*<span class="built_in">log</span>(<span class="number">1</span>-sigmoid(X*theta)));</div></pre></td></tr></table></figure></p>
<p><strong>Gradient Descent for Logistic Regression</strong><br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">theta=((sigmoid(X*theta)-y)'*X)/m;</div></pre></td></tr></table></figure></p>
<p><strong>Predict Function</strong><br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">p(<span class="built_in">find</span>(sigmoid(X*theta)&gt;=<span class="number">0.5</span>))=<span class="number">1</span>;</div></pre></td></tr></table></figure></p>
<p><strong>Compute Cost for Regularized LR</strong><br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">idx=<span class="built_in">length</span>(theta);</div><div class="line">J=sum((-y)'*<span class="built_in">log</span>(sigmoid(X*theta))-(<span class="number">1</span>-y)'*<span class="built_in">log</span>(<span class="number">1</span>-sigmoid(X*theta)))/m+...</div><div class="line">    sum(theta(<span class="number">2</span>:idx).^<span class="number">2</span>)*lambda/(<span class="number">2</span>*m);</div></pre></td></tr></table></figure></p>
<p><strong>Gradient Descent for Regularized LR</strong><br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">idx=<span class="built_in">length</span>(theta);</div><div class="line">theta(<span class="number">1</span>)=(X'(<span class="number">1</span>,:)*(sigmoid(X*theta)-y))/m;</div><div class="line">theta(<span class="number">2</span>:idx)=(X'(<span class="number">2</span>:idx,:)*(sigmoid(X*theta)-y))/m+(lambda/m)*theta(<span class="number">2</span>:idx);</div></pre></td></tr></table></figure></p>
<h2 id="Week-4-Multi-class-Classification-and-Neural-Networks"><a href="#Week-4-Multi-class-Classification-and-Neural-Networks" class="headerlink" title="Week 4: Multi-class Classification and Neural Networks"></a>Week 4: Multi-class Classification and Neural Networks</h2><p><strong>Regularized Logistic Regression</strong><br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">idx=<span class="built_in">length</span>(theta);</div><div class="line">J=sum((-y)'*<span class="built_in">log</span>(sigmoid(X*theta))-(<span class="number">1</span>-y)'*<span class="built_in">log</span>(<span class="number">1</span>-sigmoid(X*theta)))/m+...</div><div class="line">    sum(theta(<span class="number">2</span>:idx).^<span class="number">2</span>)*lambda/(<span class="number">2</span>*m);</div><div class="line">theta(<span class="number">1</span>)=(X'(<span class="number">1</span>,:)*(sigmoid(X*theta)-y))/m;</div><div class="line">theta(<span class="number">2</span>:idx)=(X'(<span class="number">2</span>:idx,:)*(sigmoid(X*theta)-y))/m+(lambda/m)*theta(<span class="number">2</span>:idx);</div></pre></td></tr></table></figure></p>
<p><strong>One-vs-All Classifier Training</strong><br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> c=<span class="number">1</span>:num_labels</div><div class="line">  initial_theta = <span class="built_in">zeros</span>(n + <span class="number">1</span>, <span class="number">1</span>);</div><div class="line">  options = optimset(<span class="string">'GradObj'</span>, <span class="string">'on'</span>, <span class="string">'MaxIter'</span>, <span class="number">50</span>);</div><div class="line">  [theta, J, exit_flag]=fmincg(@(t)(lrCostFunction(t,X,(y==c),lambda)),...</div><div class="line">                        initial_theta, options);</div><div class="line">  all_theta(c,:)=theta(:);</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure></p>
<p><strong>One-vs-All Classifier Prediction</strong><br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">result=sigmoid(X*all_theta');</div><div class="line">[value,p]=max(result,[],<span class="number">2</span>);</div></pre></td></tr></table></figure></p>
<p><strong>Neural Network Prediction Function</strong><br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">X=[ones(size(X,<span class="number">1</span>),<span class="number">1</span>) X];</div><div class="line">layer2=sigmoid(X*Theta1');</div><div class="line">layer2=[ones(size(X,<span class="number">1</span>),<span class="number">1</span>) layer2];</div><div class="line">output=sigmoid(layer2*Theta2');</div><div class="line">[value,p]=max(output,[],<span class="number">2</span>);</div></pre></td></tr></table></figure></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/03/06/2017-03-06-Machine-Learning-Review/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mike">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Deep Learning Journey">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/03/06/2017-03-06-Machine-Learning-Review/" itemprop="url">
                  Review After 1 Week Learning
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-03-06T00:00:00+11:00">
                2017-03-06
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Deep-Learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/03/06/2017-03-06-Machine-Learning-Review/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2017/03/06/2017-03-06-Machine-Learning-Review/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

          
        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>Completed 4 weeks’ learning content of Andrew Ng’s Machine Learing course on Coursera within 1 week. Here’re some lesson learnt.</p>
</blockquote>
<p>At the first beginning, all things went to Caculus, Linear Algebra, Probality, which learnt many years ago. And so many terms there like CNN, RNN, MLP, RBM, back propagation. After going through Machine <strong>Learning Recipes</strong> from google and <strong>Deep Learning Simplified</strong> from TODSI, there’re so many questions in my mind. I think Andrew Ng’s course is a very handy tool that connect my previous experience with new concept, which introduces some hands-on assignments to make it more understandable.</p>
<p>Before the course, it would be better if you know something like Matrix operations (e.g. transpose and inverse), basic Caculus (e.g. derivative and polynormial). If not, it’s fine because all these would be mentioned in the course. It’s very important to practice the various operations using Matlab or Octave. <strong>Size</strong> is a very handy function or command to verify if everything will be OK.</p>
<p>I’m a little bit confused between vectorized implementation and for loop implementation. And then I found vectorized implementation is easier than loop, as long as finished relevant parts of Linear Algebra.<br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">m = <span class="built_in">length</span>(y);</div><div class="line"></div><div class="line">J = ((X*theta-y)'*(X*theta-y))/(<span class="number">2</span> * m);</div><div class="line"></div><div class="line">J = sum((X*theta-y).^<span class="number">2</span>)/(<span class="number">2</span> * m);</div></pre></td></tr></table></figure></p>
<p>both formulas lead to the same result, but vectorized one is better on performance side, and more concise.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cost function: J(theta)</div><div class="line">gradient descent: theta</div></pre></td></tr></table></figure>
<h2 id="Features-Normalization"><a href="#Features-Normalization" class="headerlink" title="Features Normalization"></a>Features Normalization</h2><p><em>Features Normalization</em> is essential for Linear Regression and Logistic Regression. It always can be done by introducing <em>Mean</em> and <em>Standard Deviation</em> functions.</p>
<blockquote>
<p><strong>Normalized Value</strong> equals (X-mean(X))./std(X)</p>
</blockquote>
<p><strong>Sigmoid</strong> function is a vital activation function using in afterwards neural network implementation.</p>
<blockquote>
<p>g=ones(size(z))./(1+exp(-z))</p>
</blockquote>
<p><a href="https://au.mathworks.com/help/matlab/ref/find.html" target="_blank" rel="external">find</a> and <a href="https://au.mathworks.com/help/matlab/ref/max.html" target="_blank" rel="external">max</a> function are very useful for determing the result of a multi-class classifier.</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/12/23/2016-12-23-Big Data University Recognitions/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mike">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Deep Learning Journey">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/12/23/2016-12-23-Big Data University Recognitions/" itemprop="url">
                  Certifications of Big Data University
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2016-12-23T00:00:00+11:00">
                2016-12-23
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Certification/" itemprop="url" rel="index">
                    <span itemprop="name">Certification</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2016/12/23/2016-12-23-Big Data University Recognitions/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2016/12/23/2016-12-23-Big Data University Recognitions/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

          
        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>Big Data University</p>
</blockquote>
<h2 id="Big-Data-Analytics"><a href="#Big-Data-Analytics" class="headerlink" title="Big Data Analytics"></a>Big Data Analytics</h2><table>
<thead>
<tr>
<th style="text-align:center">Big Data Analytics Level 2</th>
<th style="text-align:center">Big Data Foundation Level2</th>
<th style="text-align:center">Big Data Foundation Level1</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><img src="/images/Cert/big-data-analytics-level-2.png" alt="BDA Level2"></td>
<td style="text-align:center"><img src="/images/Cert/big-data-foundations-level-2.png" alt="BDF Level2"></td>
<td style="text-align:center"><img src="/images/Cert/big-data-foundations-level-1.png" alt="BDF Level1"></td>
</tr>
</tbody>
</table>
<h2 id="Data-Science"><a href="#Data-Science" class="headerlink" title="Data Science"></a>Data Science</h2><table>
<thead>
<tr>
<th style="text-align:center">Data Science Level 2</th>
<th style="text-align:center">Data Science Level1</th>
<th style="text-align:center">Data Science for Business Level1</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><img src="/images/Cert/data-science-foundations-level-2.png" alt=""></td>
<td style="text-align:center"><img src="/images/Cert/data-science-foundations-level-1.png" alt="Data Science for Foundation Level1"></td>
<td style="text-align:center"><img src="/images/Cert/data-science-for-business-level-1.png" alt="Data Dcience for Dusiness Level1"></td>
</tr>
</tbody>
</table>
<h2 id="Watson-Analytics"><a href="#Watson-Analytics" class="headerlink" title="Watson Analytics"></a>Watson Analytics</h2><p><img src="/images/Cert/watson-analytics-level-1.png" alt="Watson Analytics Level1"></p>
<h2 id="Text-Analytics"><a href="#Text-Analytics" class="headerlink" title="Text Analytics"></a>Text Analytics</h2><table>
<thead>
<tr>
<th style="text-align:center">Text Analytics Level2</th>
<th style="text-align:center">Text Analytics Level 1</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><img src="/images/Cert/text-analytics-level-2.png" alt=""></td>
<td style="text-align:center"><img src="/images/Cert/text-analytics-level-1.png" alt="Text Analyltics Level1"></td>
</tr>
</tbody>
</table>
<h2 id="Scala-Programming"><a href="#Scala-Programming" class="headerlink" title="Scala Programming"></a>Scala Programming</h2><table>
<thead>
<tr>
<th style="text-align:center">Scala Programming for Data Science Level2</th>
<th style="text-align:center">Scala Programming for Data Science Level1</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><img src="/images/Cert/scala-programming-for-data-science-level-2.png" alt="Scala Programming for Data Science Level2"></td>
<td style="text-align:center"><img src="/images/Cert/scala-programming-for-data-science-level-1.png" alt="Scala Programming for Data Science Level1"></td>
</tr>
</tbody>
</table>
<h2 id="Hadoop-amp-Spark"><a href="#Hadoop-amp-Spark" class="headerlink" title="Hadoop &amp; Spark"></a>Hadoop &amp; Spark</h2><table>
<thead>
<tr>
<th style="text-align:center">Spark Level1</th>
<th style="text-align:center">Hadoop Foundation Level1</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><img src="/images/Cert/spark-level-1.png" alt="Spark Level1"></td>
<td style="text-align:center"><img src="/images/Cert/hadoop-foundations-level-1.png" alt="Haddop Foundation Level1"></td>
</tr>
</tbody>
</table>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/05/31/svm/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mike">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Deep Learning Journey">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/05/31/svm/" itemprop="url">
                  Support Vector Machine
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2016-05-31T00:00:00+10:00">
                2016-05-31
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/cs231n/" itemprop="url" rel="index">
                    <span itemprop="name">cs231n</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2016/05/31/svm/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2016/05/31/svm/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

          
        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Multiclass-Support-Vector-Machine-exercise"><a href="#Multiclass-Support-Vector-Machine-exercise" class="headerlink" title="Multiclass Support Vector Machine exercise"></a>Multiclass Support Vector Machine exercise</h1><p><em>Complete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission. For more details see the <a href="http://vision.stanford.edu/teaching/cs231n/assignments.html" target="_blank" rel="external">assignments page</a> on the course website.</em></p>
<p>In this exercise you will:</p>
<ul>
<li>implement a fully-vectorized <strong>loss function</strong> for the SVM</li>
<li>implement the fully-vectorized expression for its <strong>analytic gradient</strong></li>
<li><strong>check your implementation</strong> using numerical gradient</li>
<li>use a validation set to <strong>tune the learning rate and regularization</strong> strength</li>
<li><strong>optimize</strong> the loss function with <strong>SGD</strong></li>
<li><strong>visualize</strong> the final learned weights</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Run some setup code for this notebook.</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> random</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> cs231n.data_utils <span class="keyword">import</span> load_CIFAR10</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</div><div class="line"></div><div class="line"><span class="comment"># This is a bit of magic to make matplotlib figures appear inline in the</span></div><div class="line"><span class="comment"># notebook rather than in a new window.</span></div><div class="line">%matplotlib inline</div><div class="line">plt.rcParams[<span class="string">'figure.figsize'</span>] = (<span class="number">10.0</span>, <span class="number">8.0</span>) <span class="comment"># set default size of plots</span></div><div class="line">plt.rcParams[<span class="string">'image.interpolation'</span>] = <span class="string">'nearest'</span></div><div class="line">plt.rcParams[<span class="string">'image.cmap'</span>] = <span class="string">'gray'</span></div><div class="line"></div><div class="line"><span class="comment"># Some more magic so that the notebook will reload external python modules;</span></div><div class="line"><span class="comment"># see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython</span></div><div class="line">%load_ext autoreload</div><div class="line">%autoreload <span class="number">2</span></div></pre></td></tr></table></figure>
<h2 id="CIFAR-10-Data-Loading-and-Preprocessing"><a href="#CIFAR-10-Data-Loading-and-Preprocessing" class="headerlink" title="CIFAR-10 Data Loading and Preprocessing"></a>CIFAR-10 Data Loading and Preprocessing</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Load the raw CIFAR-10 data.</span></div><div class="line">cifar10_dir = <span class="string">'cs231n/datasets/cifar-10-batches-py'</span></div><div class="line">X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)</div><div class="line"></div><div class="line"><span class="comment"># As a sanity check, we print out the size of the training and test data.</span></div><div class="line">print(<span class="string">'Training data shape: '</span>, X_train.shape)</div><div class="line">print(<span class="string">'Training labels shape: '</span>, y_train.shape)</div><div class="line">print(<span class="string">'Test data shape: '</span>, X_test.shape)</div><div class="line">print(<span class="string">'Test labels shape: '</span>, y_test.shape)</div></pre></td></tr></table></figure>
<pre><code>Training data shape:  (50000, 32, 32, 3)
Training labels shape:  (50000,)
Test data shape:  (10000, 32, 32, 3)
Test labels shape:  (10000,)
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Visualize some examples from the dataset.</span></div><div class="line"><span class="comment"># We show a few examples of training images from each class.</span></div><div class="line">classes = [<span class="string">'plane'</span>, <span class="string">'car'</span>, <span class="string">'bird'</span>, <span class="string">'cat'</span>, <span class="string">'deer'</span>, <span class="string">'dog'</span>, <span class="string">'frog'</span>, <span class="string">'horse'</span>, <span class="string">'ship'</span>, <span class="string">'truck'</span>]</div><div class="line">num_classes = len(classes)</div><div class="line">samples_per_class = <span class="number">7</span></div><div class="line"><span class="keyword">for</span> y, cls <span class="keyword">in</span> enumerate(classes):</div><div class="line">    idxs = np.flatnonzero(y_train == y)</div><div class="line">    idxs = np.random.choice(idxs, samples_per_class, replace=<span class="keyword">False</span>)</div><div class="line">    <span class="keyword">for</span> i, idx <span class="keyword">in</span> enumerate(idxs):</div><div class="line">        plt_idx = i * num_classes + y + <span class="number">1</span></div><div class="line">        plt.subplot(samples_per_class, num_classes, plt_idx)</div><div class="line">        plt.imshow(X_train[idx].astype(<span class="string">'uint8'</span>))</div><div class="line">        plt.axis(<span class="string">'off'</span>)</div><div class="line">        <span class="keyword">if</span> i == <span class="number">0</span>:</div><div class="line">            plt.title(cls)</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<p><img src="/images/cs231n/output_4_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Split the data into train, val, and test sets. In addition we will</span></div><div class="line"><span class="comment"># create a small development set as a subset of the training data;</span></div><div class="line"><span class="comment"># we can use this for development so our code runs faster.</span></div><div class="line">num_training = <span class="number">49000</span></div><div class="line">num_validation = <span class="number">1000</span></div><div class="line">num_test = <span class="number">1000</span></div><div class="line">num_dev = <span class="number">500</span></div><div class="line"></div><div class="line"><span class="comment"># Our validation set will be num_validation points from the original</span></div><div class="line"><span class="comment"># training set.</span></div><div class="line">mask = range(num_training, num_training + num_validation)</div><div class="line">X_val = X_train[mask]</div><div class="line">y_val = y_train[mask]</div><div class="line"></div><div class="line"><span class="comment"># Our training set will be the first num_train points from the original</span></div><div class="line"><span class="comment"># training set.</span></div><div class="line">mask = range(num_training)</div><div class="line">X_train = X_train[mask]</div><div class="line">y_train = y_train[mask]</div><div class="line"></div><div class="line"><span class="comment"># We will also make a development set, which is a small subset of</span></div><div class="line"><span class="comment"># the training set.</span></div><div class="line">mask = np.random.choice(num_training, num_dev, replace=<span class="keyword">False</span>)</div><div class="line">X_dev = X_train[mask]</div><div class="line">y_dev = y_train[mask]</div><div class="line"></div><div class="line"><span class="comment"># We use the first num_test points of the original test set as our</span></div><div class="line"><span class="comment"># test set.</span></div><div class="line">mask = range(num_test)</div><div class="line">X_test = X_test[mask]</div><div class="line">y_test = y_test[mask]</div><div class="line"></div><div class="line">print(<span class="string">'Train data shape: '</span>, X_train.shape)</div><div class="line">print(<span class="string">'Train labels shape: '</span>, y_train.shape)</div><div class="line">print(<span class="string">'Validation data shape: '</span>, X_val.shape)</div><div class="line">print(<span class="string">'Validation labels shape: '</span>, y_val.shape)</div><div class="line">print(<span class="string">'Test data shape: '</span>, X_test.shape)</div><div class="line">print(<span class="string">'Test labels shape: '</span>, y_test.shape)</div></pre></td></tr></table></figure>
<pre><code>Train data shape:  (49000, 32, 32, 3)
Train labels shape:  (49000,)
Validation data shape:  (1000, 32, 32, 3)
Validation labels shape:  (1000,)
Test data shape:  (1000, 32, 32, 3)
Test labels shape:  (1000,)
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Preprocessing: reshape the image data into rows</span></div><div class="line">X_train = np.reshape(X_train, (X_train.shape[<span class="number">0</span>], <span class="number">-1</span>))</div><div class="line">X_val = np.reshape(X_val, (X_val.shape[<span class="number">0</span>], <span class="number">-1</span>))</div><div class="line">X_test = np.reshape(X_test, (X_test.shape[<span class="number">0</span>], <span class="number">-1</span>))</div><div class="line">X_dev = np.reshape(X_dev, (X_dev.shape[<span class="number">0</span>], <span class="number">-1</span>))</div><div class="line"></div><div class="line"><span class="comment"># As a sanity check, print out the shapes of the data</span></div><div class="line">print(<span class="string">'Training data shape: '</span>, X_train.shape)</div><div class="line">print(<span class="string">'Validation data shape: '</span>, X_val.shape)</div><div class="line">print(<span class="string">'Test data shape: '</span>, X_test.shape)</div><div class="line">print(<span class="string">'dev data shape: '</span>, X_dev.shape)</div></pre></td></tr></table></figure>
<pre><code>Training data shape:  (49000, 3072)
Validation data shape:  (1000, 3072)
Test data shape:  (1000, 3072)
dev data shape:  (500, 3072)
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Preprocessing: subtract the mean image</span></div><div class="line"><span class="comment"># first: compute the image mean based on the training data</span></div><div class="line">mean_image = np.mean(X_train, axis=<span class="number">0</span>)</div><div class="line">print(mean_image[:<span class="number">10</span>]) <span class="comment"># print a few of the elements</span></div><div class="line">plt.figure(figsize=(<span class="number">4</span>,<span class="number">4</span>))</div><div class="line">plt.imshow(mean_image.reshape((<span class="number">32</span>,<span class="number">32</span>,<span class="number">3</span>)).astype(<span class="string">'uint8'</span>)) <span class="comment"># visualize the mean image</span></div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<pre><code>[ 130.64189796  135.98173469  132.47391837  130.05569388  135.34804082
  131.75402041  130.96055102  136.14328571  132.47636735  131.48467347]
</code></pre><p><img src="/images/cs231n/output_7_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># second: subtract the mean image from train and test data</span></div><div class="line">X_train -= mean_image</div><div class="line">X_val -= mean_image</div><div class="line">X_test -= mean_image</div><div class="line">X_dev -= mean_image</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># third: append the bias dimension of ones (i.e. bias trick) so that our SVM</span></div><div class="line"><span class="comment"># only has to worry about optimizing a single weight matrix W.</span></div><div class="line">X_train = np.hstack([X_train, np.ones((X_train.shape[<span class="number">0</span>], <span class="number">1</span>))])</div><div class="line">X_val = np.hstack([X_val, np.ones((X_val.shape[<span class="number">0</span>], <span class="number">1</span>))])</div><div class="line">X_test = np.hstack([X_test, np.ones((X_test.shape[<span class="number">0</span>], <span class="number">1</span>))])</div><div class="line">X_dev = np.hstack([X_dev, np.ones((X_dev.shape[<span class="number">0</span>], <span class="number">1</span>))])</div><div class="line"></div><div class="line">print(X_train.shape, X_val.shape, X_test.shape, X_dev.shape)</div></pre></td></tr></table></figure>
<pre><code>(49000, 3073) (1000, 3073) (1000, 3073) (500, 3073)
</code></pre><h2 id="SVM-Classifier"><a href="#SVM-Classifier" class="headerlink" title="SVM Classifier"></a>SVM Classifier</h2><p>Your code for this section will all be written inside <strong>cs231n/classifiers/linear_svm.py</strong>. </p>
<p>As you can see, we have prefilled the function <code>compute_loss_naive</code> which uses for loops to evaluate the multiclass SVM loss function. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Evaluate the naive implementation of the loss we provided for you:</span></div><div class="line"><span class="keyword">from</span> cs231n.classifiers.linear_svm <span class="keyword">import</span> svm_loss_naive</div><div class="line"><span class="keyword">import</span> time</div><div class="line"></div><div class="line"><span class="comment"># generate a random SVM weight matrix of small numbers</span></div><div class="line">W = np.random.randn(<span class="number">3073</span>, <span class="number">10</span>) * <span class="number">0.0001</span> </div><div class="line"></div><div class="line">loss, grad = svm_loss_naive(W, X_dev, y_dev, <span class="number">0.000005</span>)</div><div class="line">print(<span class="string">'loss: %f'</span> % (loss, ))</div></pre></td></tr></table></figure>
<pre><code>loss: 9.303809
</code></pre><p>The <code>grad</code> returned from the function above is right now all zero. Derive and implement the gradient for the SVM cost function and implement it inline inside the function <code>svm_loss_naive</code>. You will find it helpful to interleave your new code inside the existing function.</p>
<p>To check that you have correctly implemented the gradient correctly, you can numerically estimate the gradient of the loss function and compare the numeric estimate to the gradient that you computed. We have provided code that does this for you:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Once you've implemented the gradient, recompute it with the code below</span></div><div class="line"><span class="comment"># and gradient check it with the function we provided for you</span></div><div class="line"></div><div class="line"><span class="comment"># Compute the loss and its gradient at W.</span></div><div class="line">loss, grad = svm_loss_naive(W, X_dev, y_dev, <span class="number">0.0</span>)</div><div class="line"></div><div class="line"><span class="comment"># Numerically compute the gradient along several randomly chosen dimensions, and</span></div><div class="line"><span class="comment"># compare them with your analytically computed gradient. The numbers should match</span></div><div class="line"><span class="comment"># almost exactly along all dimensions.</span></div><div class="line"><span class="keyword">from</span> cs231n.gradient_check <span class="keyword">import</span> grad_check_sparse</div><div class="line">f = <span class="keyword">lambda</span> w: svm_loss_naive(w, X_dev, y_dev, <span class="number">0.0</span>)[<span class="number">0</span>]</div><div class="line">grad_numerical = grad_check_sparse(f, W, grad)</div><div class="line"></div><div class="line"><span class="comment"># do the gradient check once again with regularization turned on</span></div><div class="line"><span class="comment"># you didn't forget the regularization gradient did you?</span></div><div class="line">loss, grad = svm_loss_naive(W, X_dev, y_dev, <span class="number">5e1</span>)</div><div class="line">f = <span class="keyword">lambda</span> w: svm_loss_naive(w, X_dev, y_dev, <span class="number">5e1</span>)[<span class="number">0</span>]</div><div class="line">grad_numerical = grad_check_sparse(f, W, grad)</div></pre></td></tr></table></figure>
<pre><code>numerical: 16.469521 analytic: 16.506422, relative error: 1.119018e-03
numerical: 2.777627 analytic: 2.777627, relative error: 4.230158e-11
numerical: -35.023579 analytic: -35.023579, relative error: 2.770265e-13
numerical: -17.572130 analytic: -17.572130, relative error: 3.481662e-11
numerical: 22.379721 analytic: 22.439319, relative error: 1.329747e-03
numerical: 8.556768 analytic: 8.533278, relative error: 1.374502e-03
numerical: 4.156731 analytic: 4.156731, relative error: 3.875931e-11
numerical: -20.577358 analytic: -20.577358, relative error: 3.413460e-11
numerical: 8.112327 analytic: 8.112327, relative error: 1.668366e-11
numerical: -9.145706 analytic: -9.145706, relative error: 1.435659e-11
numerical: -27.741451 analytic: -27.740071, relative error: 2.488863e-05
numerical: -12.511028 analytic: -12.500920, relative error: 4.041441e-04
numerical: -16.131307 analytic: -16.128216, relative error: 9.583208e-05
numerical: 1.130680 analytic: 1.137196, relative error: 2.873276e-03
numerical: -16.035794 analytic: -16.033600, relative error: 6.842851e-05
numerical: -7.125878 analytic: -7.124353, relative error: 1.069622e-04
numerical: 5.995823 analytic: 5.991373, relative error: 3.712099e-04
numerical: 2.801756 analytic: 2.812069, relative error: 1.836995e-03
numerical: -7.504935 analytic: -7.503342, relative error: 1.061263e-04
numerical: -10.071115 analytic: -10.068544, relative error: 1.276397e-04
</code></pre><h3 id="Inline-Question-1"><a href="#Inline-Question-1" class="headerlink" title="Inline Question 1:"></a>Inline Question 1:</h3><p>It is possible that once in a while a dimension in the gradcheck will not match exactly. What could such a discrepancy be caused by? Is it a reason for concern? What is a simple example in one dimension where a gradient check could fail? <em>Hint: the SVM loss function is not strictly speaking differentiable</em></p>
<p><strong>Your Answer:</strong> <em>fill this in.</em></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Next implement the function svm_loss_vectorized; for now only compute the loss;</span></div><div class="line"><span class="comment"># we will implement the gradient in a moment.</span></div><div class="line">tic = time.time()</div><div class="line">loss_naive, grad_naive = svm_loss_naive(W, X_dev, y_dev, <span class="number">0.000005</span>)</div><div class="line">toc = time.time()</div><div class="line">print(<span class="string">'Naive loss: %e computed in %fs'</span> % (loss_naive, toc - tic))</div><div class="line"></div><div class="line"><span class="keyword">from</span> cs231n.classifiers.linear_svm <span class="keyword">import</span> svm_loss_vectorized</div><div class="line">tic = time.time()</div><div class="line">loss_vectorized, _ = svm_loss_vectorized(W, X_dev, y_dev, <span class="number">0.000005</span>)</div><div class="line">toc = time.time()</div><div class="line">print(<span class="string">'Vectorized loss: %e computed in %fs'</span> % (loss_vectorized, toc - tic))</div><div class="line"></div><div class="line"><span class="comment"># The losses should match but your vectorized implementation should be much faster.</span></div><div class="line">print(<span class="string">'difference: %f'</span> % (loss_naive - loss_vectorized))</div></pre></td></tr></table></figure>
<pre><code>Naive loss: 9.303809e+00 computed in 0.088023s
Vectorized loss: 9.303809e+00 computed in 0.000000s
difference: -0.000000
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Complete the implementation of svm_loss_vectorized, and compute the gradient</span></div><div class="line"><span class="comment"># of the loss function in a vectorized way.</span></div><div class="line"></div><div class="line"><span class="comment"># The naive implementation and the vectorized implementation should match, but</span></div><div class="line"><span class="comment"># the vectorized version should still be much faster.</span></div><div class="line">tic = time.time()</div><div class="line">_, grad_naive = svm_loss_naive(W, X_dev, y_dev, <span class="number">0.000005</span>)</div><div class="line">toc = time.time()</div><div class="line">print(<span class="string">'Naive loss and gradient: computed in %fs'</span> % (toc - tic))</div><div class="line"></div><div class="line">tic = time.time()</div><div class="line">_, grad_vectorized = svm_loss_vectorized(W, X_dev, y_dev, <span class="number">0.000005</span>)</div><div class="line">toc = time.time()</div><div class="line">print(<span class="string">'Vectorized loss and gradient: computed in %fs'</span> % (toc - tic))</div><div class="line"></div><div class="line"><span class="comment"># The loss is a single number, so it is easy to compare the values computed</span></div><div class="line"><span class="comment"># by the two implementations. The gradient on the other hand is a matrix, so</span></div><div class="line"><span class="comment"># we use the Frobenius norm to compare them.</span></div><div class="line">difference = np.linalg.norm(grad_naive - grad_vectorized, ord=<span class="string">'fro'</span>)</div><div class="line">print(<span class="string">'difference: %f'</span> % difference)</div></pre></td></tr></table></figure>
<pre><code>Naive loss and gradient: computed in 0.075697s
Vectorized loss and gradient: computed in 0.015597s
difference: 0.000000
</code></pre><h3 id="Stochastic-Gradient-Descent"><a href="#Stochastic-Gradient-Descent" class="headerlink" title="Stochastic Gradient Descent"></a>Stochastic Gradient Descent</h3><p>We now have vectorized and efficient expressions for the loss, the gradient and our gradient matches the numerical gradient. We are therefore ready to do SGD to minimize the loss.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># In the file linear_classifier.py, implement SGD in the function</span></div><div class="line"><span class="comment"># LinearClassifier.train() and then run it with the code below.</span></div><div class="line"><span class="keyword">from</span> cs231n.classifiers <span class="keyword">import</span> LinearSVM</div><div class="line">svm = LinearSVM()</div><div class="line">tic = time.time()</div><div class="line">loss_hist = svm.train(X_train, y_train, learning_rate=<span class="number">1e-7</span>, reg=<span class="number">2.5e4</span>,</div><div class="line">                      num_iters=<span class="number">1500</span>, verbose=<span class="keyword">True</span>)</div><div class="line">toc = time.time()</div><div class="line">print(<span class="string">'That took %fs'</span> % (toc - tic))</div></pre></td></tr></table></figure>
<pre><code>iteration 0 / 1500: loss 789.257333
iteration 100 / 1500: loss 474.433663
iteration 200 / 1500: loss 288.785563
iteration 300 / 1500: loss 174.999092
iteration 400 / 1500: loss 107.502575
iteration 500 / 1500: loss 67.361809
iteration 600 / 1500: loss 42.640011
iteration 700 / 1500: loss 27.460573
iteration 800 / 1500: loss 18.662340
iteration 900 / 1500: loss 13.202632
iteration 1000 / 1500: loss 10.091086
iteration 1100 / 1500: loss 8.209876
iteration 1200 / 1500: loss 6.719919
iteration 1300 / 1500: loss 6.445505
iteration 1400 / 1500: loss 6.394823
That took 10.856489s
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># A useful debugging strategy is to plot the loss as a function of</span></div><div class="line"><span class="comment"># iteration number:</span></div><div class="line">plt.plot(loss_hist)</div><div class="line">plt.xlabel(<span class="string">'Iteration number'</span>)</div><div class="line">plt.ylabel(<span class="string">'Loss value'</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<p><img src="/images/cs231n/output_19_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Write the LinearSVM.predict function and evaluate the performance on both the</span></div><div class="line"><span class="comment"># training and validation set</span></div><div class="line">y_train_pred = svm.predict(X_train)</div><div class="line">print(<span class="string">'training accuracy: %f'</span> % (np.mean(y_train == y_train_pred), ))</div><div class="line">y_val_pred = svm.predict(X_val)</div><div class="line">print(<span class="string">'validation accuracy: %f'</span> % (np.mean(y_val == y_val_pred), ))</div></pre></td></tr></table></figure>
<pre><code>training accuracy: 0.386592
validation accuracy: 0.396000
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Use the validation set to tune hyperparameters (regularization strength and</span></div><div class="line"><span class="comment"># learning rate). You should experiment with different ranges for the learning</span></div><div class="line"><span class="comment"># rates and regularization strengths; if you are careful you should be able to</span></div><div class="line"><span class="comment"># get a classification accuracy of about 0.4 on the validation set.</span></div><div class="line">learning_rates = [<span class="number">1e-7</span>, <span class="number">5e-5</span>]</div><div class="line">regularization_strengths = [<span class="number">2.5e4</span>, <span class="number">5e4</span>]</div><div class="line"></div><div class="line"><span class="comment"># results is dictionary mapping tuples of the form</span></div><div class="line"><span class="comment"># (learning_rate, regularization_strength) to tuples of the form</span></div><div class="line"><span class="comment"># (training_accuracy, validation_accuracy). The accuracy is simply the fraction</span></div><div class="line"><span class="comment"># of data points that are correctly classified.</span></div><div class="line">results = &#123;&#125;</div><div class="line">best_val = <span class="number">-1</span>   <span class="comment"># The highest validation accuracy that we have seen so far.</span></div><div class="line">best_svm = <span class="keyword">None</span> <span class="comment"># The LinearSVM object that achieved the highest validation rate.</span></div><div class="line"></div><div class="line"><span class="comment">################################################################################</span></div><div class="line"><span class="comment"># <span class="doctag">TODO:</span>                                                                        #</span></div><div class="line"><span class="comment"># Write code that chooses the best hyperparameters by tuning on the validation #</span></div><div class="line"><span class="comment"># set. For each combination of hyperparameters, train a linear SVM on the      #</span></div><div class="line"><span class="comment"># training set, compute its accuracy on the training and validation sets, and  #</span></div><div class="line"><span class="comment"># store these numbers in the results dictionary. In addition, store the best   #</span></div><div class="line"><span class="comment"># validation accuracy in best_val and the LinearSVM object that achieves this  #</span></div><div class="line"><span class="comment"># accuracy in best_svm.                                                        #</span></div><div class="line"><span class="comment">#                                                                              #</span></div><div class="line"><span class="comment"># Hint: You should use a small value for num_iters as you develop your         #</span></div><div class="line"><span class="comment"># validation code so that the SVMs don't take much time to train; once you are #</span></div><div class="line"><span class="comment"># confident that your validation code works, you should rerun the validation   #</span></div><div class="line"><span class="comment"># code with a larger value for num_iters.                                      #</span></div><div class="line"><span class="comment">################################################################################</span></div><div class="line"><span class="keyword">for</span> lr <span class="keyword">in</span> learning_rates:</div><div class="line">    <span class="keyword">for</span> rg <span class="keyword">in</span> regularization_strengths:</div><div class="line">        svm = LinearSVM()</div><div class="line">        svm.train(X_train, y_train, lr, rg, num_iters=<span class="number">1500</span>, verbose=<span class="keyword">True</span>)</div><div class="line">        y_train_pred = svm.predict(X_train)</div><div class="line">        tr_acc = np.mean(y_train == y_train_pred)</div><div class="line">        y_val_pred = svm.predict(X_val)</div><div class="line">        val_acc = np.mean(y_val == y_val_pred)</div><div class="line">        results[(lr, rg)] = (tr_acc, val_acc)</div><div class="line">        <span class="keyword">if</span> ( val_acc &gt; best_val ):</div><div class="line">            best_val = val_acc</div><div class="line">            best_svm = svm</div><div class="line"><span class="comment">################################################################################</span></div><div class="line"><span class="comment">#                              END OF YOUR CODE                                #</span></div><div class="line"><span class="comment">################################################################################</span></div><div class="line">    </div><div class="line"><span class="comment"># Print out results.</span></div><div class="line"><span class="keyword">for</span> lr, reg <span class="keyword">in</span> sorted(results):</div><div class="line">    train_accuracy, val_accuracy = results[(lr, reg)]</div><div class="line">    print(<span class="string">'lr %e reg %e train accuracy: %f val accuracy: %f'</span> % (</div><div class="line">                lr, reg, train_accuracy, val_accuracy))</div><div class="line">    </div><div class="line">print(<span class="string">'best validation accuracy achieved during cross-validation: %f'</span> % best_val)</div></pre></td></tr></table></figure>
<pre><code>iteration 0 / 1500: loss 789.065547
iteration 100 / 1500: loss 471.869885
iteration 200 / 1500: loss 287.571321
iteration 300 / 1500: loss 174.971822
iteration 400 / 1500: loss 107.469640
iteration 500 / 1500: loss 66.592478
iteration 600 / 1500: loss 42.744517
iteration 700 / 1500: loss 27.970961
iteration 800 / 1500: loss 18.784138
iteration 900 / 1500: loss 13.689656
iteration 1000 / 1500: loss 10.442484
iteration 1100 / 1500: loss 8.628084
iteration 1200 / 1500: loss 7.651019
iteration 1300 / 1500: loss 7.293839
iteration 1400 / 1500: loss 5.511511
iteration 0 / 1500: loss 1550.430617
iteration 100 / 1500: loss 562.861074
iteration 200 / 1500: loss 208.088357
iteration 300 / 1500: loss 79.631242
iteration 400 / 1500: loss 32.613426
iteration 500 / 1500: loss 15.668765
iteration 600 / 1500: loss 9.829078
iteration 700 / 1500: loss 7.445856
iteration 800 / 1500: loss 6.173443
iteration 900 / 1500: loss 6.113765
iteration 1000 / 1500: loss 5.975592
iteration 1100 / 1500: loss 5.387827
iteration 1200 / 1500: loss 5.588608
iteration 1300 / 1500: loss 5.674135
iteration 1400 / 1500: loss 5.963768
iteration 0 / 1500: loss 792.729407
iteration 100 / 1500: loss 1579.061351
iteration 200 / 1500: loss 1597.839939
iteration 300 / 1500: loss 1424.967120
iteration 400 / 1500: loss 1529.863606
iteration 500 / 1500: loss 1258.660893
iteration 600 / 1500: loss 1644.842874
iteration 700 / 1500: loss 2002.318904
iteration 800 / 1500: loss 1490.452012
iteration 900 / 1500: loss 1267.799186
iteration 1000 / 1500: loss 1549.189446
iteration 1100 / 1500: loss 1535.982962
iteration 1200 / 1500: loss 1723.197882
iteration 1300 / 1500: loss 1408.466663
iteration 1400 / 1500: loss 1455.262473
iteration 0 / 1500: loss 1580.196494
iteration 100 / 1500: loss 949896886740740888349276520281192529920.000000
iteration 200 / 1500: loss 157010347728952709449921947103514933633509000849464615932473424373283291136.000000
iteration 300 / 1500: loss 25952552996097017356836306605428792509291628371727204641788179815139964999252799930083323091275200922183008256.000000
iteration 400 / 1500: loss 4289749158303560641273429876840821741916329739931744152247811985408643225971254099801842360067613937792299693665749721282745823647908289117683712.000000
iteration 500 / 1500: loss 709061179604702431604478689092232735396837552975623276663328382864987824732940841365409902650479223051854498214810866215640377531869293279580106538877948236994685349250255959359488.000000
iteration 600 / 1500: loss 117202134173560512521419626315205903596028294657793384350230825370408277624688170535290826414468622274653649482360439361664694381269017661906980637148514938669692585682506296502226877872853086668002787511144519041024.000000
iteration 700 / 1500: loss 19372574116235231605329654536466951141155031198658397320172851358352873475962630864659477288725487656049983446645961246296694900601894763161226394889968338751317161334426274301451631181274371175411931901011506576866703308660580045706135449878285778944.000000
iteration 800 / 1500: loss 3202131347994600294784809323742756460620361866728467171214593468739369428195943124081756468395181490557712587636480852301195660384408688885987713393372049979280723972564620455428679171099866829713311076783546671751404167208979248377105801094390703988702367044969105876814753143688527872.000000


C:\Users\micha\PycharmProjects\cs231n\cs231n\classifiers\linear_svm.py:84: RuntimeWarning: overflow encountered in double_scalars
  loss += reg * np.sum(W*W)
C:\Users\micha\PycharmProjects\cs231n\cs231n\classifiers\linear_svm.py:84: RuntimeWarning: overflow encountered in multiply
  loss += reg * np.sum(W*W)


iteration 900 / 1500: loss inf
iteration 1000 / 1500: loss inf
iteration 1100 / 1500: loss inf
iteration 1200 / 1500: loss inf
iteration 1300 / 1500: loss inf
iteration 1400 / 1500: loss inf
lr 1.000000e-07 reg 2.500000e+04 train accuracy: 0.378000 val accuracy: 0.382000
lr 1.000000e-07 reg 5.000000e+04 train accuracy: 0.363347 val accuracy: 0.364000
lr 5.000000e-05 reg 2.500000e+04 train accuracy: 0.175714 val accuracy: 0.155000
lr 5.000000e-05 reg 5.000000e+04 train accuracy: 0.058531 val accuracy: 0.058000
best validation accuracy achieved during cross-validation: 0.382000
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Visualize the cross-validation results</span></div><div class="line"><span class="keyword">import</span> math</div><div class="line">x_scatter = [math.log10(x[<span class="number">0</span>]) <span class="keyword">for</span> x <span class="keyword">in</span> results]</div><div class="line">y_scatter = [math.log10(x[<span class="number">1</span>]) <span class="keyword">for</span> x <span class="keyword">in</span> results]</div><div class="line"></div><div class="line"><span class="comment"># plot training accuracy</span></div><div class="line">marker_size = <span class="number">100</span></div><div class="line">colors = [results[x][<span class="number">0</span>] <span class="keyword">for</span> x <span class="keyword">in</span> results]</div><div class="line">plt.subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>)</div><div class="line">plt.scatter(x_scatter, y_scatter, marker_size, c=colors)</div><div class="line">plt.colorbar()</div><div class="line">plt.xlabel(<span class="string">'log learning rate'</span>)</div><div class="line">plt.ylabel(<span class="string">'log regularization strength'</span>)</div><div class="line">plt.title(<span class="string">'CIFAR-10 training accuracy'</span>)</div><div class="line"></div><div class="line"><span class="comment"># plot validation accuracy</span></div><div class="line">colors = [results[x][<span class="number">1</span>] <span class="keyword">for</span> x <span class="keyword">in</span> results] <span class="comment"># default size of markers is 20</span></div><div class="line">plt.subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>)</div><div class="line">plt.scatter(x_scatter, y_scatter, marker_size, c=colors)</div><div class="line">plt.colorbar()</div><div class="line">plt.xlabel(<span class="string">'log learning rate'</span>)</div><div class="line">plt.ylabel(<span class="string">'log regularization strength'</span>)</div><div class="line">plt.title(<span class="string">'CIFAR-10 validation accuracy'</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<p><img src="/images/cs231n/output_22_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Evaluate the best svm on test set</span></div><div class="line">y_test_pred = best_svm.predict(X_test)</div><div class="line">test_accuracy = np.mean(y_test == y_test_pred)</div><div class="line">print(<span class="string">'linear SVM on raw pixels final test set accuracy: %f'</span> % test_accuracy)</div></pre></td></tr></table></figure>
<pre><code>linear SVM on raw pixels final test set accuracy: 0.376000
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Visualize the learned weights for each class.</span></div><div class="line"><span class="comment"># Depending on your choice of learning rate and regularization strength, these may</span></div><div class="line"><span class="comment"># or may not be nice to look at.</span></div><div class="line">w = best_svm.W[:<span class="number">-1</span>,:] <span class="comment"># strip out the bias</span></div><div class="line">w = w.reshape(<span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>, <span class="number">10</span>)</div><div class="line">w_min, w_max = np.min(w), np.max(w)</div><div class="line">classes = [<span class="string">'plane'</span>, <span class="string">'car'</span>, <span class="string">'bird'</span>, <span class="string">'cat'</span>, <span class="string">'deer'</span>, <span class="string">'dog'</span>, <span class="string">'frog'</span>, <span class="string">'horse'</span>, <span class="string">'ship'</span>, <span class="string">'truck'</span>]</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</div><div class="line">    plt.subplot(<span class="number">2</span>, <span class="number">5</span>, i + <span class="number">1</span>)</div><div class="line">      </div><div class="line">    <span class="comment"># Rescale the weights to be between 0 and 255</span></div><div class="line">    wimg = <span class="number">255.0</span> * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min)</div><div class="line">    plt.imshow(wimg.astype(<span class="string">'uint8'</span>))</div><div class="line">    plt.axis(<span class="string">'off'</span>)</div><div class="line">    plt.title(classes[i])</div></pre></td></tr></table></figure>
<p><img src="/images/cs231n/output_24_0.png" alt="png"></p>
<h3 id="Inline-question-2"><a href="#Inline-question-2" class="headerlink" title="Inline question 2:"></a>Inline question 2:</h3><p>Describe what your visualized SVM weights look like, and offer a brief explanation for why they look they way that they do.</p>
<p><strong>Your answer:</strong> <em>fill this in</em></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/05/19/knn solution/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mike">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Deep Learning Journey">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/05/19/knn solution/" itemprop="url">
                  K-Nearest Neighbor
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2016-05-19T00:00:00+10:00">
                2016-05-19
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/cs231n/" itemprop="url" rel="index">
                    <span itemprop="name">cs231n</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2016/05/19/knn solution/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2016/05/19/knn solution/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

          
        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>Below is the solution for assignment 1 of cs231n course</p>
</blockquote>
<p>It took a whole day to complete this assignment. :-(</p>
<h2 id="KNN-py"><a href="#KNN-py" class="headerlink" title="KNN.py"></a>KNN.py</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div><div class="line">208</div><div class="line">209</div><div class="line">210</div><div class="line">211</div><div class="line">212</div><div class="line">213</div><div class="line">214</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</div><div class="line"></div><div class="line"><span class="keyword">import</span> random</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> cs231n.data_utils <span class="keyword">import</span> load_CIFAR10</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">time_function</span><span class="params">(f, *args)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    Call a function f with args and return the time (in seconds) that it took to execute.</div><div class="line">    """</div><div class="line">    <span class="keyword">import</span> time</div><div class="line">    tic = time.time()</div><div class="line">    f(*args)</div><div class="line">    toc = time.time()</div><div class="line">    <span class="keyword">return</span> toc - tic</div><div class="line"></div><div class="line"></div><div class="line">plt.rcParams[<span class="string">'figure.figsize'</span>] = (<span class="number">10.0</span>, <span class="number">8.0</span>) <span class="comment"># set default size of plots</span></div><div class="line">plt.rcParams[<span class="string">'image.interpolation'</span>] = <span class="string">'nearest'</span></div><div class="line">plt.rcParams[<span class="string">'image.cmap'</span>] = <span class="string">'gray'</span></div><div class="line"></div><div class="line"><span class="comment"># Load the raw CIFAR-10 data.</span></div><div class="line">cifar10_dir = <span class="string">'cs231n/datasets/cifar-10-batches-py'</span></div><div class="line">X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)</div><div class="line"></div><div class="line"><span class="comment"># As a sanity check, we print out the size of the training and test data.</span></div><div class="line">print(<span class="string">'Training data shape: '</span>, X_train.shape)</div><div class="line">print(<span class="string">'Training labels shape: '</span>, y_train.shape)</div><div class="line">print(<span class="string">'Test data shape: '</span>, X_test.shape)</div><div class="line">print(<span class="string">'Test labels shape: '</span>, y_test.shape)</div><div class="line"></div><div class="line"><span class="comment"># Visualize some examples from the dataset.</span></div><div class="line"><span class="comment"># We show a few examples of training images from each class.</span></div><div class="line">classes = [<span class="string">'plane'</span>, <span class="string">'car'</span>, <span class="string">'bird'</span>, <span class="string">'cat'</span>, <span class="string">'deer'</span>, <span class="string">'dog'</span>, <span class="string">'frog'</span>, <span class="string">'horse'</span>, <span class="string">'ship'</span>, <span class="string">'truck'</span>]</div><div class="line">num_classes = len(classes)</div><div class="line">samples_per_class = <span class="number">7</span></div><div class="line"><span class="keyword">for</span> y, cls <span class="keyword">in</span> enumerate(classes):</div><div class="line">    idxs = np.flatnonzero(y_train == y)</div><div class="line">    idxs = np.random.choice(idxs, samples_per_class, replace=<span class="keyword">False</span>)</div><div class="line">    <span class="keyword">for</span> i, idx <span class="keyword">in</span> enumerate(idxs):</div><div class="line">        plt_idx = i * num_classes + y + <span class="number">1</span></div><div class="line">        plt.subplot(samples_per_class, num_classes, plt_idx)</div><div class="line">        plt.imshow(X_train[idx].astype(<span class="string">'uint8'</span>))</div><div class="line">        plt.axis(<span class="string">'off'</span>)</div><div class="line">        <span class="keyword">if</span> i == <span class="number">0</span>:</div><div class="line">            plt.title(cls)</div><div class="line">plt.show()</div><div class="line"></div><div class="line"><span class="comment"># Subsample the data for more efficient code execution in this exercise</span></div><div class="line">num_training = <span class="number">5000</span></div><div class="line">mask = list(range(num_training))</div><div class="line">X_train = X_train[mask]</div><div class="line">y_train = y_train[mask]</div><div class="line"></div><div class="line">num_test = <span class="number">500</span></div><div class="line">mask = list(range(num_test))</div><div class="line">X_test = X_test[mask]</div><div class="line">y_test = y_test[mask]</div><div class="line"></div><div class="line"><span class="comment"># Reshape the image data into rows</span></div><div class="line">X_train = np.reshape(X_train, (X_train.shape[<span class="number">0</span>], <span class="number">-1</span>))</div><div class="line">X_test = np.reshape(X_test, (X_test.shape[<span class="number">0</span>], <span class="number">-1</span>))</div><div class="line">print(X_train.shape, X_test.shape)</div><div class="line"></div><div class="line"><span class="keyword">from</span> cs231n.classifiers <span class="keyword">import</span> KNearestNeighbor</div><div class="line"></div><div class="line"><span class="comment"># Create a kNN classifier instance.</span></div><div class="line"><span class="comment"># Remember that training a kNN classifier is a noop:</span></div><div class="line"><span class="comment"># the Classifier simply remembers the data and does no further processing</span></div><div class="line">classifier = KNearestNeighbor()</div><div class="line">classifier.train(X_train, y_train)</div><div class="line"></div><div class="line">dists = classifier.compute_distances_two_loops(X_test)</div><div class="line">print(dists.shape)</div><div class="line">plt.imshow(dists, interpolation=<span class="string">'none'</span>)</div><div class="line">plt.show()</div><div class="line"></div><div class="line"><span class="comment"># Now implement the function predict_labels and run the code below:</span></div><div class="line"><span class="comment"># # We use k = 1 (which is Nearest Neighbor).</span></div><div class="line">y_test_pred = classifier.predict_labels(dists, k=<span class="number">1</span>)</div><div class="line"></div><div class="line"><span class="comment"># Compute and print the fraction of correctly predicted examples</span></div><div class="line">num_correct = np.sum(y_test_pred == y_test)</div><div class="line">accuracy = float(num_correct) / num_test</div><div class="line">print(<span class="string">'Got %d / %d correct =&gt; accuracy: %f'</span> % (num_correct, num_test, accuracy))</div><div class="line"></div><div class="line">y_test_pred = classifier.predict_labels(dists, k=<span class="number">5</span>)</div><div class="line">num_correct = np.sum(y_test_pred == y_test)</div><div class="line">accuracy = float(num_correct) / num_test</div><div class="line">print(<span class="string">'Got %d / %d correct =&gt; accuracy: %f'</span> % (num_correct, num_test, accuracy))</div><div class="line"></div><div class="line"><span class="comment"># Now lets speed up distance matrix computation by using partial vectorization</span></div><div class="line"><span class="comment"># with one loop. Implement the function compute_distances_one_loop and run the</span></div><div class="line"><span class="comment"># code below:</span></div><div class="line">dists_one = classifier.compute_distances_one_loop(X_test)</div><div class="line"></div><div class="line"><span class="comment"># To ensure that our vectorized implementation is correct, we make sure that it</span></div><div class="line"><span class="comment"># agrees with the naive implementation. There are many ways to decide whether</span></div><div class="line"><span class="comment"># two matrices are similar; one of the simplest is the Frobenius norm. In case</span></div><div class="line"><span class="comment"># you haven't seen it before, the Frobenius norm of two matrices is the square</span></div><div class="line"><span class="comment"># root of the squared sum of differences of all elements; in other words, reshape</span></div><div class="line"><span class="comment"># the matrices into vectors and compute the Euclidean distance between them.</span></div><div class="line">difference = np.linalg.norm(dists - dists_one, ord=<span class="string">'fro'</span>)</div><div class="line">print(<span class="string">'Difference was: %f'</span> % (difference, ))</div><div class="line"><span class="keyword">if</span> difference &lt; <span class="number">0.001</span>:</div><div class="line">    print(<span class="string">'Good! The distance matrices are the same'</span>)</div><div class="line"><span class="keyword">else</span>:</div><div class="line">    print(<span class="string">'Uh-oh! The distance matrices are different'</span>)</div><div class="line"></div><div class="line"><span class="comment"># Now implement the fully vectorized version inside compute_distances_no_loops</span></div><div class="line"><span class="comment"># and run the code</span></div><div class="line">dists_two = classifier.compute_distances_no_loops(X_test)</div><div class="line"></div><div class="line"><span class="comment"># check that the distance matrix agrees with the one we computed before:</span></div><div class="line">difference = np.linalg.norm(dists - dists_two, ord=<span class="string">'fro'</span>)</div><div class="line">print(<span class="string">'Difference was: %f'</span> % (difference, ))</div><div class="line"><span class="keyword">if</span> difference &lt; <span class="number">0.001</span>:</div><div class="line">    print(<span class="string">'Good! The distance matrices are the same'</span>)</div><div class="line"><span class="keyword">else</span>:</div><div class="line">    print(<span class="string">'Uh-oh! The distance matrices are different'</span>)</div><div class="line"></div><div class="line"></div><div class="line">two_loop_time = time_function(classifier.compute_distances_two_loops, X_test)</div><div class="line">print(<span class="string">'Two loop version took %f seconds'</span> % two_loop_time)</div><div class="line"></div><div class="line">one_loop_time = time_function(classifier.compute_distances_one_loop, X_test)</div><div class="line">print(<span class="string">'One loop version took %f seconds'</span> % one_loop_time)</div><div class="line"></div><div class="line">no_loop_time = time_function(classifier.compute_distances_no_loops, X_test)</div><div class="line">print(<span class="string">'No loop version took %f seconds'</span> % no_loop_time)</div><div class="line"></div><div class="line">num_folds = <span class="number">5</span></div><div class="line">k_choices = [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">8</span>, <span class="number">10</span>, <span class="number">12</span>, <span class="number">15</span>, <span class="number">20</span>, <span class="number">50</span>, <span class="number">100</span>]</div><div class="line"></div><div class="line">X_train_folds = []</div><div class="line">y_train_folds = []</div><div class="line"><span class="comment">################################################################################</span></div><div class="line"><span class="comment"># <span class="doctag">TODO:</span>                                                                        #</span></div><div class="line"><span class="comment"># Split up the training data into folds. After splitting, X_train_folds and    #</span></div><div class="line"><span class="comment"># y_train_folds should each be lists of length num_folds, where                #</span></div><div class="line"><span class="comment"># y_train_folds[i] is the label vector for the points in X_train_folds[i].     #</span></div><div class="line"><span class="comment"># Hint: Look up the numpy array_split function.                                #</span></div><div class="line"><span class="comment">################################################################################</span></div><div class="line">X_train_folds=np.array_split(X_train,num_folds)</div><div class="line">y_train_folds=np.array_split(y_train,num_folds)</div><div class="line"><span class="comment">################################################################################</span></div><div class="line"><span class="comment">#                                 END OF YOUR CODE                             #</span></div><div class="line"><span class="comment">################################################################################</span></div><div class="line"></div><div class="line"><span class="comment"># A dictionary holding the accuracies for different values of k that we find</span></div><div class="line"><span class="comment"># when running cross-validation. After running cross-validation,</span></div><div class="line"><span class="comment"># k_to_accuracies[k] should be a list of length num_folds giving the different</span></div><div class="line"><span class="comment"># accuracy values that we found when using that value of k.</span></div><div class="line">k_to_accuracies = &#123;&#125;</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">################################################################################</span></div><div class="line"><span class="comment"># <span class="doctag">TODO:</span>                                                                        #</span></div><div class="line"><span class="comment"># Perform k-fold cross validation to find the best value of k. For each        #</span></div><div class="line"><span class="comment"># possible value of k, run the k-nearest-neighbor algorithm num_folds times,   #</span></div><div class="line"><span class="comment"># where in each case you use all but one of the folds as training data and the #</span></div><div class="line"><span class="comment"># last fold as a validation set. Store the accuracies for all fold and all     #</span></div><div class="line"><span class="comment"># values of k in the k_to_accuracies dictionary.                               #</span></div><div class="line"><span class="comment">################################################################################</span></div><div class="line">num_test = num_training/ num_folds</div><div class="line"><span class="keyword">for</span> k <span class="keyword">in</span> k_choices:</div><div class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> range(num_folds):</div><div class="line">        X_train_fold = np.vstack(X_train_folds[<span class="number">0</span>:batch]+X_train_folds[batch+<span class="number">1</span>:])</div><div class="line">        y_train_fold = np.hstack(y_train_folds[<span class="number">0</span>:batch]+y_train_folds[batch+<span class="number">1</span>:])</div><div class="line"></div><div class="line">        classifier = KNearestNeighbor()</div><div class="line">        classifier.train(X_train_fold, y_train_fold)</div><div class="line">        y_test_pred = classifier.predict(X_train_folds[batch], k)</div><div class="line">        num_correct = np.sum(y_test_pred == y_train_folds[batch])</div><div class="line">        accuracy = float(num_correct) / num_test</div><div class="line">        k_to_accuracies.setdefault(k,[]).append(accuracy)</div><div class="line"><span class="comment">################################################################################</span></div><div class="line"><span class="comment">#                                 END OF YOUR CODE                             #</span></div><div class="line"><span class="comment">################################################################################</span></div><div class="line"></div><div class="line"><span class="comment"># Print out the computed accuracies</span></div><div class="line"><span class="keyword">for</span> k <span class="keyword">in</span> sorted(k_to_accuracies):</div><div class="line">    <span class="keyword">for</span> accuracy <span class="keyword">in</span> k_to_accuracies[k]:</div><div class="line">        print(<span class="string">'k = %d, accuracy = %f'</span> % (k, accuracy))</div><div class="line"><span class="comment"># plot the raw observations</span></div><div class="line"><span class="keyword">for</span> k <span class="keyword">in</span> k_choices:</div><div class="line">    accuracies = k_to_accuracies[k]</div><div class="line">    plt.scatter([k] * len(accuracies), accuracies)</div><div class="line"></div><div class="line"><span class="comment"># plot the trend line with error bars that correspond to standard deviation</span></div><div class="line">accuracies_mean = np.array([np.mean(v) <span class="keyword">for</span> k,v <span class="keyword">in</span> sorted(k_to_accuracies.items())])</div><div class="line">accuracies_std = np.array([np.std(v) <span class="keyword">for</span> k,v <span class="keyword">in</span> sorted(k_to_accuracies.items())])</div><div class="line">plt.errorbar(k_choices, accuracies_mean, yerr=accuracies_std)</div><div class="line">plt.title(<span class="string">'Cross-validation on k'</span>)</div><div class="line">plt.xlabel(<span class="string">'k'</span>)</div><div class="line">plt.ylabel(<span class="string">'Cross-validation accuracy'</span>)</div><div class="line">plt.show()</div><div class="line"></div><div class="line"><span class="comment"># Based on the cross-validation results above, choose the best value for k,</span></div><div class="line"><span class="comment"># retrain the classifier using all the training data, and test it on the test</span></div><div class="line"><span class="comment"># data. You should be able to get above 28% accuracy on the test data.</span></div><div class="line">best_k = <span class="number">10</span></div><div class="line">num_test=<span class="number">500</span></div><div class="line"></div><div class="line">classifier = KNearestNeighbor()</div><div class="line">classifier.train(X_train, y_train)</div><div class="line">y_test_pred = classifier.predict(X_test, k=best_k)</div><div class="line"></div><div class="line"><span class="comment"># Compute and display the accuracy</span></div><div class="line">num_correct = np.sum(y_test_pred == y_test)</div><div class="line">accuracy = float(num_correct) / num_test</div><div class="line">print(<span class="string">'Got %d / %d correct =&gt; accuracy: %f'</span> % (num_correct, num_test, accuracy))</div></pre></td></tr></table></figure>
<h2 id="k-nearest-neighbor-py"><a href="#k-nearest-neighbor-py" class="headerlink" title="k_nearest_neighbor.py"></a>k_nearest_neighbor.py</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> past.builtins <span class="keyword">import</span> xrange</div><div class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> mode</div><div class="line"></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">KNearestNeighbor</span><span class="params">(object)</span>:</span></div><div class="line">  <span class="string">""" a kNN classifier with L2 distance """</span></div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></div><div class="line">    <span class="keyword">pass</span></div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self, X, y)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    Train the classifier. For k-nearest neighbors this is just </div><div class="line">    memorizing the training data.</div><div class="line"></div><div class="line">    Inputs:</div><div class="line">    - X: A numpy array of shape (num_train, D) containing the training data</div><div class="line">      consisting of num_train samples each of dimension D.</div><div class="line">    - y: A numpy array of shape (N,) containing the training labels, where</div><div class="line">         y[i] is the label for X[i].</div><div class="line">    """</div><div class="line">    self.X_train = X</div><div class="line">    self.y_train = y</div><div class="line">    </div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, X, k=<span class="number">1</span>, num_loops=<span class="number">0</span>)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    Predict labels for test data using this classifier.</div><div class="line"></div><div class="line">    Inputs:</div><div class="line">    - X: A numpy array of shape (num_test, D) containing test data consisting</div><div class="line">         of num_test samples each of dimension D.</div><div class="line">    - k: The number of nearest neighbors that vote for the predicted labels.</div><div class="line">    - num_loops: Determines which implementation to use to compute distances</div><div class="line">      between training points and testing points.</div><div class="line"></div><div class="line">    Returns:</div><div class="line">    - y: A numpy array of shape (num_test,) containing predicted labels for the</div><div class="line">      test data, where y[i] is the predicted label for the test point X[i].  </div><div class="line">    """</div><div class="line">    <span class="keyword">if</span> num_loops == <span class="number">0</span>:</div><div class="line">      dists = self.compute_distances_no_loops(X)</div><div class="line">    <span class="keyword">elif</span> num_loops == <span class="number">1</span>:</div><div class="line">      dists = self.compute_distances_one_loop(X)</div><div class="line">    <span class="keyword">elif</span> num_loops == <span class="number">2</span>:</div><div class="line">      dists = self.compute_distances_two_loops(X)</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">      <span class="keyword">raise</span> ValueError(<span class="string">'Invalid value %d for num_loops'</span> % num_loops)</div><div class="line"></div><div class="line">    <span class="keyword">return</span> self.predict_labels(dists, k=k)</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">compute_distances_two_loops</span><span class="params">(self, X)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    Compute the distance between each test point in X and each training point</div><div class="line">    in self.X_train using a nested loop over both the training data and the </div><div class="line">    test data.</div><div class="line"></div><div class="line">    Inputs:</div><div class="line">    - X: A numpy array of shape (num_test, D) containing test data.</div><div class="line"></div><div class="line">    Returns:</div><div class="line">    - dists: A numpy array of shape (num_test, num_train) where dists[i, j]</div><div class="line">      is the Euclidean distance between the ith test point and the jth training</div><div class="line">      point.</div><div class="line">    """</div><div class="line">    num_test = X.shape[<span class="number">0</span>]</div><div class="line">    num_train = self.X_train.shape[<span class="number">0</span>]</div><div class="line">    dists = np.zeros((num_test, num_train))</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> xrange(num_test):</div><div class="line">      <span class="keyword">for</span> j <span class="keyword">in</span> xrange(num_train):</div><div class="line">        <span class="comment">#####################################################################</span></div><div class="line">        <span class="comment"># <span class="doctag">TODO:</span>                                                             #</span></div><div class="line">        <span class="comment"># Compute the l2 distance between the ith test point and the jth    #</span></div><div class="line">        <span class="comment"># training point, and store the result in dists[i, j]. You should   #</span></div><div class="line">        <span class="comment"># not use a loop over dimension.                                    #</span></div><div class="line">        <span class="comment">#####################################################################</span></div><div class="line">        dists[i,j] = np.sqrt(np.sum(np.square(self.X_train[j,:]-X[i,:]), axis = <span class="number">0</span>))</div><div class="line">        <span class="comment">#####################################################################</span></div><div class="line">        <span class="comment">#                       END OF YOUR CODE                            #</span></div><div class="line">        <span class="comment">#####################################################################</span></div><div class="line">    <span class="keyword">return</span> dists</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">compute_distances_one_loop</span><span class="params">(self, X)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    Compute the distance between each test point in X and each training point</div><div class="line">    in self.X_train using a single loop over the test data.</div><div class="line"></div><div class="line">    Input / Output: Same as compute_distances_two_loops</div><div class="line">    """</div><div class="line">    num_test = X.shape[<span class="number">0</span>]</div><div class="line">    num_train = self.X_train.shape[<span class="number">0</span>]</div><div class="line">    dists = np.zeros((num_test, num_train))</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> xrange(num_test):</div><div class="line">      <span class="comment">#######################################################################</span></div><div class="line">      <span class="comment"># <span class="doctag">TODO:</span>                                                               #</span></div><div class="line">      <span class="comment"># Compute the l2 distance between the ith test point and all training #</span></div><div class="line">      <span class="comment"># points, and store the result in dists[i, :].                        #</span></div><div class="line">      <span class="comment">#######################################################################</span></div><div class="line">      dists[i,:] = np.sqrt(np.sum(np.square(self.X_train[:]-X[i,:]),axis=<span class="number">1</span>))</div><div class="line">      <span class="comment">#######################################################################</span></div><div class="line">      <span class="comment">#                         END OF YOUR CODE                            #</span></div><div class="line">      <span class="comment">#######################################################################</span></div><div class="line">    <span class="keyword">return</span> dists</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">compute_distances_no_loops</span><span class="params">(self, X)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    Compute the distance between each test point in X and each training point</div><div class="line">    in self.X_train using no explicit loops.</div><div class="line"></div><div class="line">    Input / Output: Same as compute_distances_two_loops</div><div class="line">    """</div><div class="line">    num_test = X.shape[<span class="number">0</span>]</div><div class="line">    num_train = self.X_train.shape[<span class="number">0</span>]</div><div class="line">    dists = np.zeros((num_test, num_train)) </div><div class="line">    <span class="comment">#########################################################################</span></div><div class="line">    <span class="comment"># <span class="doctag">TODO:</span>                                                                 #</span></div><div class="line">    <span class="comment"># Compute the l2 distance between all test points and all training      #</span></div><div class="line">    <span class="comment"># points without using any explicit loops, and store the result in      #</span></div><div class="line">    <span class="comment"># dists.                                                                #</span></div><div class="line">    <span class="comment">#                                                                       #</span></div><div class="line">    <span class="comment"># You should implement this function using only basic array operations; #</span></div><div class="line">    <span class="comment"># in particular you should not use functions from scipy.                #</span></div><div class="line">    <span class="comment">#                                                                       #</span></div><div class="line">    <span class="comment"># HINT: Try to formulate the l2 distance using matrix multiplication    #</span></div><div class="line">    <span class="comment">#       and two broadcast sums.                                         #</span></div><div class="line">    <span class="comment">#########################################################################</span></div><div class="line">    dists = np.sqrt(np.sum(np.square(self.X_train),axis=<span class="number">1</span>)+np.sum(np.square(X),axis=<span class="number">1</span>,keepdims=<span class="keyword">True</span>)<span class="number">-2</span>*X.dot(self.X_train.T))</div><div class="line">    <span class="comment">#########################################################################</span></div><div class="line">    <span class="comment">#                         END OF YOUR CODE                              #</span></div><div class="line">    <span class="comment">#########################################################################</span></div><div class="line">    <span class="keyword">return</span> dists</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">predict_labels</span><span class="params">(self, dists, k=<span class="number">1</span>)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    Given a matrix of distances between test points and training points,</div><div class="line">    predict a label for each test point.</div><div class="line"></div><div class="line">    Inputs:</div><div class="line">    - dists: A numpy array of shape (num_test, num_train) where dists[i, j]</div><div class="line">      gives the distance betwen the ith test point and the jth training point.</div><div class="line"></div><div class="line">    Returns:</div><div class="line">    - y: A numpy array of shape (num_test,) containing predicted labels for the</div><div class="line">      test data, where y[i] is the predicted label for the test point X[i].  </div><div class="line">    """</div><div class="line">    num_test = dists.shape[<span class="number">0</span>]</div><div class="line">    y_pred = np.zeros(num_test)</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> xrange(num_test):</div><div class="line">      <span class="comment"># A list of length k storing the labels of the k nearest neighbors to</span></div><div class="line">      <span class="comment"># the ith test point.</span></div><div class="line">      closest_y = []</div><div class="line">      <span class="comment">#########################################################################</span></div><div class="line">      <span class="comment"># <span class="doctag">TODO:</span>                                                                 #</span></div><div class="line">      <span class="comment"># Use the distance matrix to find the k nearest neighbors of the ith    #</span></div><div class="line">      <span class="comment"># testing point, and use self.y_train to find the labels of these       #</span></div><div class="line">      <span class="comment"># neighbors. Store these labels in closest_y.                           #</span></div><div class="line">      <span class="comment"># Hint: Look up the function numpy.argsort.                             #</span></div><div class="line">      <span class="comment">#########################################################################</span></div><div class="line">      closest_y=np.argsort(dists[i,:])</div><div class="line">      <span class="comment">#########################################################################</span></div><div class="line">      <span class="comment"># <span class="doctag">TODO:</span>                                                                 #</span></div><div class="line">      <span class="comment"># Now that you have found the labels of the k nearest neighbors, you    #</span></div><div class="line">      <span class="comment"># need to find the most common label in the list closest_y of labels.   #</span></div><div class="line">      <span class="comment"># Store this label in y_pred[i]. Break ties by choosing the smaller     #</span></div><div class="line">      <span class="comment"># label.                                                                #</span></div><div class="line">      <span class="comment">#########################################################################</span></div><div class="line">      y_pred[i]=mode(self.y_train[closest_y[:k]])[<span class="number">0</span>][<span class="number">0</span>]</div><div class="line">      <span class="comment">#########################################################################</span></div><div class="line">      <span class="comment">#                           END OF YOUR CODE                            # </span></div><div class="line">      <span class="comment">#########################################################################</span></div><div class="line"></div><div class="line">    <span class="keyword">return</span> y_pred</div></pre></td></tr></table></figure>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/05/03/A-blog-based-on-HEXO/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mike">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Deep Learning Journey">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/05/03/A-blog-based-on-HEXO/" itemprop="url">
                  A blog based on HEXO, theme NEXT
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2016-05-03T15:56:20+10:00">
                2016-05-03
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2016/05/03/A-blog-based-on-HEXO/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2016/05/03/A-blog-based-on-HEXO/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

          
        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>Github + HEXO + NEXT on Windows 10 64bit</p>
</blockquote>
<h2 id="Pre-requisite"><a href="#Pre-requisite" class="headerlink" title="Pre-requisite"></a>Pre-requisite</h2><p>Before installation, it’s a must to install</p>
<ul>
<li>Node.js</li>
<li>Git</li>
</ul>
<h2 id="Install-HEXO"><a href="#Install-HEXO" class="headerlink" title="Install HEXO"></a>Install HEXO</h2><p>Open Git Bash, type in or execute:<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">npm install -g hexo-cli</div></pre></td></tr></table></figure></p>
<p>if success, then create a local directory, let’s say “deepai”, enter “deepai” and then execute below commands:<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">hexo init</div><div class="line">npm install</div></pre></td></tr></table></figure></p>
<p>structure of deepai directory looks like:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">.</div><div class="line">|-- node_modules</div><div class="line">|-- scaffolds </div><div class="line">|-- source</div><div class="line">|-- themes</div><div class="line">|-- _config.yml</div><div class="line">|-- package.json</div></pre></td></tr></table></figure></p>
<p>then execute:<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hexo s</div></pre></td></tr></table></figure></p>
<p>if message shows “Hexo is running at <a href="http://localhost:4000/" target="_blank" rel="external">http://localhost:4000/</a>“, then open web browser to access the url, the hello world page shows if everything goes well.</p>
<h2 id="Change-Theme-and-Deployment"><a href="#Change-Theme-and-Deployment" class="headerlink" title="Change Theme and Deployment"></a>Change Theme and Deployment</h2><p>Execute below command to install theme “next”<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git clone https://github.com/iissnan/hexo-theme-next themes/next</div></pre></td></tr></table></figure></p>
<p>Open configuration file __config.yml, find Section “Deployment”<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">deploy:</div><div class="line">  type: Git</div><div class="line">  repo: git@github.com/**username**/**reponame**.github.io</div></pre></td></tr></table></figure></p>
<p>Search keyword “theme” or Section “Extension”, update corresponding part to<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">theme: next</div></pre></td></tr></table></figure></p>
<p>Execute below command to start local server<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hexo s</div></pre></td></tr></table></figure></p>
<p>Open web browser to verify if settings are OK. If yes, execute command<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">npm install hexo-deployer-git --save //install git plugin</div><div class="line">hexo g -d //deploy on Git Pages</div></pre></td></tr></table></figure></p>
<p>to complete the deployment.</p>
<h2 id="Language"><a href="#Language" class="headerlink" title="Language"></a>Language</h2><p>If you want to change the blog’s language, just modify language part within section Site in __config.yml file.</p>
<h2 id="Theme-Settings"><a href="#Theme-Settings" class="headerlink" title="Theme Settings"></a>Theme Settings</h2><p>Scheme, Menu, Tags and sidebar can be changed by changing the relevant variables within __config.yml under theme/next directory.</p>
<p><strong>NEXT</strong> theme supports Disqus and mathjax, these third party plugins can be turned on in __config.yml, as long as you have set the shortname of Disqus.<br>$$a^2+b^2=c^2$$</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  


          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="Mike" />
          <p class="site-author-name" itemprop="name">Mike</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">10</span>
                <span class="site-state-item-name">posts</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">4</span>
                <span class="site-state-item-name">categories</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">6</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Mike</span>
</div>


<div class="powered-by">
  Powered by <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>


        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>


        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  

    
      <script id="dsq-count-scr" src="https://dlfsi.disqus.com/count.js" async></script>
    

    

  




	





  





  








  





  

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
